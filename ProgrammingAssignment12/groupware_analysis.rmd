---
title: 'Groupware Accelerometer Data Analysis'
author: "Tolu Omotunde"
date: "29/Sep/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
mode: selfcontained
hitheme: tomorrow
highlighter: highlight.js
widgets: mathjax
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
```

## Abstract  
This report uses a dataset which generated by accelerometers in different body parts of participants who took part in an exercise.  
  
## Loads the libraries used in this report  
```{r, message=FALSE, cache=TRUE}
library(caret)
```

## Loads the dataset into memory  
```{r, cache=TRUE}
train_data <- read.csv('data/pml_training.csv')
test_data <- read.csv('data/pml_testing.csv')
```  
  
## Perform some exploration on answering structure  
```{r, cache=TRUE}
'problem_id' %in% names(test_data)
'problem_id' %in% names(train_data)
'classe' %in% names(test_data)
'classe' %in% names(train_data)
unique(train_data$classe)
```
## Data cleaning  
After performing some other exploratory analysis on the dataset, I decided to use only the sensor measurements for prediction.  
* Removes useless variables  
```{r, cache=TRUE}
variables_to_be_removed <- c(
    'X',
    'user_name',
    'raw_timestamp_part_1',
    'raw_timestamp_part_2',
    'cvtd_timestamp',
    'new_window',
    'num_window'
)
remove_columns_by_name <- function (dataset, columns) {
    for (variable in columns) {
        dataset[variable] <- NULL
    }
    dataset
}
dim(train_data)
dim(test_data)
train_data <- remove_columns_by_name(train_data, variables_to_be_removed)
test_data <- remove_columns_by_name(test_data, variables_to_be_removed)
dim(train_data)
dim(test_data)
```
  
* Gets the problem_id(s) from the test dataset and classe from the train dataset  
```{r, cache=TRUE}
ids <- as.data.frame(test_data$problem_id)
labels <- as.data.frame(as.factor(train_data$classe))
train_data$classe <- NULL
test_data$problem_id <- NULL
```
  
* Converts all values to numeric* Convert values in the dataset into numeric ones  
```{r, message=FALSE, cache=TRUE}
convert_to_numeric <- function(x) {
    as.numeric(as.character(x))
}
numeric_factor <- function(dataset) {
    data.frame(sapply(dataset, function (col) {
        convert_to_numeric(col)
    }))
}
train_data <- numeric_factor(train_data)
test_data <- numeric_factor(test_data)
```
  
* Center and scale  
```{r, cache=TRUE}
preprocessed_train <- preProcess(train_data, method=c('center', 'scale'))
train_data <- predict(preprocessed_train, train_data)
test_data <- predict(preprocessed_train, test_data)
```
  
* Deals with missing values, remove columns with zero variance  
```{r, cache=TRUE}
variables_to_be_removed <- c(
    'kurtosis_yaw_belt',
    'skewness_yaw_belt',
    'kurtosis_yaw_dumbbell',
    'skewness_yaw_dumbbell',
    'kurtosis_yaw_forearm',
    'skewness_yaw_forearmThese',
    'amplitude_yaw_belt',
    'amplitude_yaw_dumbbell',
    'amplitude_yaw_forearm'
)
train_data <- remove_columns_by_name(train_data, variables_to_be_removed)
test_data <- remove_columns_by_name(test_data, variables_to_be_removed)
median_missing <- function (dataset) {
    dataset <- dataset[, colSums(is.na(dataset)) == 0]
    dataset
}
train_data <- median_missing(train_data)
test_data <- median_missing(test_data)
dim(train_data)
dim(test_data)
```
  
* Dimension reduction using PCA  
```{r, cache=TRUE}
reduced_data <- preProcess(train_data, method='pca', thresh=0.90)
train_data <- predict(reduced_data, train_data)
test_data <- predict(reduced_data, test_data)
dim(train_data)
dim(test_data)
```
  
* Re-attaches labels to the train data  
```{r, cache=TRUE}
names(labels) <- 'labels'
train_data <- cbind(labels, train_data)
dim(train_data)
```
  
* Cross validation  
For this step, I split the training dataset into two parts with ratio of 7:3.  
```{r, cache=TRUE}
splited <- createDataPartition(y=train_data$labels, p=0.7, list=FALSE)
cross_train <- train_data[splited, ]
cross_test <- train_data[-splited, ]
dim(cross_test)
dim(cross_train)
```
  
* Trains the model with vary methods (will choose later)  
```{r, echo=FALSE, cache=TRUE}
available_algorithms = c('gbm', 'rf')
my_algorithm = available_algorithms[2]
fit_model <- train(labels ~ ., method=my_algorithm, data=cross_train)
```
  
* Generate the prediction with the trained model  
```{r, cache=TRUE}
prediction <- predict(fit_model, cross_test[, -1])
```
  
* Calculate the accuracy  
```{r, cache=TRUE}
accuracy <- sum((prediction == cross_test$label)) / length(cross_test$label)
print(paste('Accuracy is:', accuracy))
```
  
The accuracy is just 80% for the gbm, I will try with random forest later.  
With the RF, the result is 97%, that's high!  
Btw with the random forest I got 95% score.  
  
* Just for easier visualization, I parse the output into a csv file  
```{r, cache=TRUE}
result <- predict(fit_model, test_data)
result <- as.data.frame(result)
output <- data.frame(problem_id = ids, label = result)
write.csv(output, file = paste('result/output.csv', sep=''), row.names = FALSE)
```